{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "236d0e40-f0cc-4a9c-b8ae-acce0310ce62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\programming\\languages\\python\\python313\\lib\\site-packages (4.57.1)\n",
      "Requirement already satisfied: datasets in c:\\programming\\languages\\python\\python313\\lib\\site-packages (4.2.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\programming\\languages\\python\\python313\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: filelock in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from transformers) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from datasets) (2.3.0)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.1)\n",
      "Requirement already satisfied: anyio in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from scikit-learn) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: colorama in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69946894-f94f-4160-9529-ddd4f69aaa03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.9.0-cp313-cp313-win_amd64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: filelock in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: setuptools in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programming\\languages\\python\\python313\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.9.0-cp313-cp313-win_amd64.whl (109.3 MB)\n",
      "   ---------------------------------------- 0.0/109.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/109.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/109.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/109.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/109.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/109.3 MB 478.5 kB/s eta 0:03:48\n",
      "   ---------------------------------------- 1.0/109.3 MB 920.4 kB/s eta 0:01:58\n",
      "    --------------------------------------- 1.6/109.3 MB 1.2 MB/s eta 0:01:29\n",
      "    --------------------------------------- 2.6/109.3 MB 1.8 MB/s eta 0:01:00\n",
      "   - -------------------------------------- 3.4/109.3 MB 2.1 MB/s eta 0:00:50\n",
      "   - -------------------------------------- 4.5/109.3 MB 2.4 MB/s eta 0:00:44\n",
      "   - -------------------------------------- 5.2/109.3 MB 2.6 MB/s eta 0:00:41\n",
      "   -- ------------------------------------- 6.0/109.3 MB 2.7 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 6.8/109.3 MB 2.8 MB/s eta 0:00:37\n",
      "   -- ------------------------------------- 7.6/109.3 MB 2.9 MB/s eta 0:00:36\n",
      "   --- ------------------------------------ 8.4/109.3 MB 3.0 MB/s eta 0:00:34\n",
      "   --- ------------------------------------ 8.7/109.3 MB 2.9 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 8.9/109.3 MB 2.8 MB/s eta 0:00:36\n",
      "   --- ------------------------------------ 8.9/109.3 MB 2.8 MB/s eta 0:00:36\n",
      "   --- ------------------------------------ 9.4/109.3 MB 2.6 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 9.7/109.3 MB 2.5 MB/s eta 0:00:40\n",
      "   --- ------------------------------------ 10.2/109.3 MB 2.4 MB/s eta 0:00:41\n",
      "   ---- ----------------------------------- 11.0/109.3 MB 2.5 MB/s eta 0:00:39\n",
      "   ---- ----------------------------------- 12.1/109.3 MB 2.6 MB/s eta 0:00:37\n",
      "   ---- ----------------------------------- 12.6/109.3 MB 2.7 MB/s eta 0:00:37\n",
      "   ---- ----------------------------------- 13.4/109.3 MB 2.7 MB/s eta 0:00:36\n",
      "   ----- ---------------------------------- 14.2/109.3 MB 2.7 MB/s eta 0:00:35\n",
      "   ----- ---------------------------------- 14.9/109.3 MB 2.8 MB/s eta 0:00:35\n",
      "   ----- ---------------------------------- 15.7/109.3 MB 2.8 MB/s eta 0:00:34\n",
      "   ------ --------------------------------- 16.8/109.3 MB 2.9 MB/s eta 0:00:33\n",
      "   ------ --------------------------------- 17.6/109.3 MB 2.9 MB/s eta 0:00:32\n",
      "   ------ --------------------------------- 18.1/109.3 MB 2.9 MB/s eta 0:00:32\n",
      "   ------ --------------------------------- 18.4/109.3 MB 2.9 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 19.1/109.3 MB 2.9 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 19.4/109.3 MB 2.8 MB/s eta 0:00:33\n",
      "   ------- -------------------------------- 20.2/109.3 MB 2.8 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 20.7/109.3 MB 2.8 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 21.0/109.3 MB 2.8 MB/s eta 0:00:32\n",
      "   -------- ------------------------------- 22.0/109.3 MB 2.8 MB/s eta 0:00:32\n",
      "   -------- ------------------------------- 22.8/109.3 MB 2.8 MB/s eta 0:00:31\n",
      "   -------- ------------------------------- 23.9/109.3 MB 2.9 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 24.6/109.3 MB 2.9 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 25.2/109.3 MB 2.9 MB/s eta 0:00:29\n",
      "   --------- ------------------------------ 26.5/109.3 MB 3.0 MB/s eta 0:00:28\n",
      "   --------- ------------------------------ 27.0/109.3 MB 3.0 MB/s eta 0:00:28\n",
      "   ---------- ----------------------------- 27.5/109.3 MB 3.0 MB/s eta 0:00:28\n",
      "   ---------- ----------------------------- 28.0/109.3 MB 2.9 MB/s eta 0:00:28\n",
      "   ---------- ----------------------------- 28.3/109.3 MB 2.9 MB/s eta 0:00:28\n",
      "   ---------- ----------------------------- 29.4/109.3 MB 2.9 MB/s eta 0:00:28\n",
      "   ----------- ---------------------------- 30.4/109.3 MB 3.0 MB/s eta 0:00:27\n",
      "   ----------- ---------------------------- 31.2/109.3 MB 3.0 MB/s eta 0:00:27\n",
      "   ----------- ---------------------------- 31.7/109.3 MB 3.0 MB/s eta 0:00:26\n",
      "   ----------- ---------------------------- 32.5/109.3 MB 3.0 MB/s eta 0:00:26\n",
      "   ----------- ---------------------------- 32.8/109.3 MB 3.0 MB/s eta 0:00:26\n",
      "   ------------ --------------------------- 33.0/109.3 MB 3.0 MB/s eta 0:00:26\n",
      "   ------------ --------------------------- 33.3/109.3 MB 2.9 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 34.1/109.3 MB 2.9 MB/s eta 0:00:26\n",
      "   ------------ --------------------------- 35.1/109.3 MB 2.9 MB/s eta 0:00:26\n",
      "   ------------ --------------------------- 35.4/109.3 MB 2.9 MB/s eta 0:00:26\n",
      "   ------------- -------------------------- 35.7/109.3 MB 2.9 MB/s eta 0:00:26\n",
      "   ------------- -------------------------- 35.7/109.3 MB 2.9 MB/s eta 0:00:26\n",
      "   ------------- -------------------------- 35.9/109.3 MB 2.8 MB/s eta 0:00:26\n",
      "   ------------- -------------------------- 35.9/109.3 MB 2.8 MB/s eta 0:00:26\n",
      "   ------------- -------------------------- 36.7/109.3 MB 2.8 MB/s eta 0:00:27\n",
      "   ------------- -------------------------- 37.5/109.3 MB 2.8 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 38.5/109.3 MB 2.8 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 39.3/109.3 MB 2.8 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 40.1/109.3 MB 2.9 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 40.9/109.3 MB 2.9 MB/s eta 0:00:24\n",
      "   --------------- ------------------------ 41.7/109.3 MB 2.9 MB/s eta 0:00:24\n",
      "   --------------- ------------------------ 42.7/109.3 MB 2.9 MB/s eta 0:00:23\n",
      "   --------------- ------------------------ 43.0/109.3 MB 2.9 MB/s eta 0:00:23\n",
      "   ---------------- ----------------------- 44.0/109.3 MB 2.9 MB/s eta 0:00:23\n",
      "   ---------------- ----------------------- 44.8/109.3 MB 2.9 MB/s eta 0:00:22\n",
      "   ---------------- ----------------------- 45.4/109.3 MB 2.9 MB/s eta 0:00:22\n",
      "   ---------------- ----------------------- 45.9/109.3 MB 2.9 MB/s eta 0:00:22\n",
      "   ---------------- ----------------------- 46.4/109.3 MB 2.9 MB/s eta 0:00:22\n",
      "   ----------------- ---------------------- 47.2/109.3 MB 2.9 MB/s eta 0:00:22\n",
      "   ----------------- ---------------------- 48.0/109.3 MB 2.9 MB/s eta 0:00:21\n",
      "   ----------------- ---------------------- 48.5/109.3 MB 2.9 MB/s eta 0:00:21\n",
      "   ----------------- ---------------------- 48.8/109.3 MB 2.9 MB/s eta 0:00:21\n",
      "   ------------------ --------------------- 49.5/109.3 MB 2.9 MB/s eta 0:00:21\n",
      "   ------------------ --------------------- 49.8/109.3 MB 2.9 MB/s eta 0:00:21\n",
      "   ------------------ --------------------- 50.1/109.3 MB 2.9 MB/s eta 0:00:21\n",
      "   ------------------ --------------------- 50.6/109.3 MB 2.9 MB/s eta 0:00:21\n",
      "   ------------------ --------------------- 50.9/109.3 MB 2.9 MB/s eta 0:00:21\n",
      "   ------------------ --------------------- 51.6/109.3 MB 2.9 MB/s eta 0:00:21\n",
      "   ------------------ --------------------- 51.9/109.3 MB 2.8 MB/s eta 0:00:21\n",
      "   ------------------- -------------------- 52.4/109.3 MB 2.8 MB/s eta 0:00:21\n",
      "   ------------------- -------------------- 52.7/109.3 MB 2.8 MB/s eta 0:00:21\n",
      "   ------------------- -------------------- 53.2/109.3 MB 2.8 MB/s eta 0:00:20\n",
      "   ------------------- -------------------- 54.0/109.3 MB 2.8 MB/s eta 0:00:20\n",
      "   -------------------- ------------------- 55.1/109.3 MB 2.8 MB/s eta 0:00:20\n",
      "   -------------------- ------------------- 55.8/109.3 MB 2.9 MB/s eta 0:00:19\n",
      "   -------------------- ------------------- 56.6/109.3 MB 2.9 MB/s eta 0:00:19\n",
      "   --------------------- ------------------ 57.4/109.3 MB 2.9 MB/s eta 0:00:19\n",
      "   --------------------- ------------------ 58.5/109.3 MB 2.9 MB/s eta 0:00:18\n",
      "   --------------------- ------------------ 59.2/109.3 MB 2.9 MB/s eta 0:00:18\n",
      "   --------------------- ------------------ 60.0/109.3 MB 2.9 MB/s eta 0:00:17\n",
      "   ---------------------- ----------------- 60.8/109.3 MB 2.9 MB/s eta 0:00:17\n",
      "   ---------------------- ----------------- 61.6/109.3 MB 2.9 MB/s eta 0:00:17\n",
      "   ---------------------- ----------------- 62.1/109.3 MB 2.9 MB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 62.9/109.3 MB 2.9 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 63.2/109.3 MB 2.9 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 63.7/109.3 MB 2.9 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 64.7/109.3 MB 2.9 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 65.8/109.3 MB 2.9 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 66.6/109.3 MB 3.0 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 67.4/109.3 MB 3.0 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 68.2/109.3 MB 3.0 MB/s eta 0:00:14\n",
      "   ------------------------- -------------- 68.9/109.3 MB 3.0 MB/s eta 0:00:14\n",
      "   ------------------------- -------------- 70.0/109.3 MB 3.0 MB/s eta 0:00:14\n",
      "   ------------------------- -------------- 70.8/109.3 MB 3.0 MB/s eta 0:00:13\n",
      "   -------------------------- ------------- 71.6/109.3 MB 3.0 MB/s eta 0:00:13\n",
      "   -------------------------- ------------- 72.4/109.3 MB 3.0 MB/s eta 0:00:13\n",
      "   -------------------------- ------------- 73.1/109.3 MB 3.0 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 74.2/109.3 MB 3.0 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 75.0/109.3 MB 3.0 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 75.0/109.3 MB 3.0 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 75.0/109.3 MB 3.0 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 75.5/109.3 MB 3.0 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 76.5/109.3 MB 3.0 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 77.3/109.3 MB 3.0 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 78.1/109.3 MB 3.0 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 78.9/109.3 MB 3.0 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 80.0/109.3 MB 3.0 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 80.7/109.3 MB 3.0 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 81.5/109.3 MB 3.0 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 82.3/109.3 MB 3.0 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 83.1/109.3 MB 3.0 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 84.1/109.3 MB 3.1 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 84.4/109.3 MB 3.1 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 85.5/109.3 MB 3.1 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 85.7/109.3 MB 3.1 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 86.2/109.3 MB 3.0 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 87.3/109.3 MB 3.1 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 88.3/109.3 MB 3.1 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 89.1/109.3 MB 3.1 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 89.7/109.3 MB 3.1 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 89.9/109.3 MB 3.1 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 90.2/109.3 MB 3.1 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 90.2/109.3 MB 3.1 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 90.4/109.3 MB 3.0 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 90.7/109.3 MB 3.0 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 91.2/109.3 MB 3.0 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 92.0/109.3 MB 3.1 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 93.1/109.3 MB 3.1 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 93.8/109.3 MB 3.1 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 94.6/109.3 MB 3.1 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 95.4/109.3 MB 3.1 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 96.2/109.3 MB 3.1 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 97.0/109.3 MB 3.1 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 97.3/109.3 MB 3.1 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 97.8/109.3 MB 3.0 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 97.8/109.3 MB 3.0 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 98.0/109.3 MB 3.0 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 98.6/109.3 MB 3.0 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 99.1/109.3 MB 3.0 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 99.4/109.3 MB 3.0 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 99.9/109.3 MB 3.0 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 100.1/109.3 MB 3.0 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 100.4/109.3 MB 3.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 101.2/109.3 MB 3.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 101.7/109.3 MB 3.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 102.0/109.3 MB 3.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 102.2/109.3 MB 3.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 102.8/109.3 MB 3.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 103.5/109.3 MB 2.9 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 104.3/109.3 MB 3.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 104.6/109.3 MB 2.9 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 104.9/109.3 MB 2.9 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 105.1/109.3 MB 2.9 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 105.9/109.3 MB 2.9 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 106.2/109.3 MB 2.9 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 106.4/109.3 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  106.7/109.3 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  107.0/109.3 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  107.2/109.3 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  107.5/109.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  107.5/109.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  107.5/109.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  107.5/109.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  107.7/109.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  108.3/109.3 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  108.8/109.3 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  109.1/109.3 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  109.1/109.3 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 109.3/109.3 MB 2.7 MB/s  0:00:39\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-2.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b0b75fe-bc3f-4a87-aa26-27850280f0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install accelerate>=0.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b9feb02-f9de-42c5-bde0-f6df0df9a3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84105d91-d374-4f49-87e0-ba9554798884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Text             Intent\n",
      "0             I want to apply for BTech 2025  admission_process\n",
      "1  What is the eligibility for MTech course?        eligibility\n",
      "2             How much are the fees for MBA?          fees_info\n",
      "3    When will admission forms be available?    admission_dates\n",
      "4                    My name is Rahul Sharma          user_info\n",
      "Index(['Text', 'Intent'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Intent.csv')\n",
    "\n",
    "print(df.head())\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b91336d9-46f7-4b09-aec1-bb09017dea2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Text             Intent  label\n",
      "0             I want to apply for BTech 2025  admission_process      0\n",
      "1  What is the eligibility for MTech course?        eligibility      1\n",
      "2             How much are the fees for MBA?          fees_info      2\n",
      "3    When will admission forms be available?    admission_dates      3\n",
      "4                    My name is Rahul Sharma          user_info      4\n"
     ]
    }
   ],
   "source": [
    "intent_labels = {label: i for i, label in enumerate(df['Intent'].unique())}\n",
    "\n",
    "df['label'] = df['Intent'].map(intent_labels)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbc2a292-0499-4932-b265-cca6202bf94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'labels'],\n",
      "    num_rows: 124\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df['Text'].tolist(),\n",
    "    df['label'].tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "train_dataset = Dataset.from_dict({\"text\": train_texts, \"labels\": train_labels})\n",
    "test_dataset = Dataset.from_dict({\"text\": test_texts, \"labels\": test_labels})\n",
    "\n",
    "print(train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea3897d4-6a9d-4f27-9fde-1d1654176943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71e218c6ada349a28b5e0fcada13a63a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/124 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80fc6f5f7f61470bb5fff484b9ea5f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/32 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True)\n",
    "\n",
    "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15ee555d-6f3a-4167-a74b-f1cc4877d505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels = len(intent_labels)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "163f2675-bdff-4df1-b9b3-0dc6d71bfd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=2,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    use_cpu=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da94931d-b924-47e6-989f-bb9a03e6c966",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7b0e770-1514-40b5-baa7-f9ba58b8125a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='930' max='930' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [930/930 09:58, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.488500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.336800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.290200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.227900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.248600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.163500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.830700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.678700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.151300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.614300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.939000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.707400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.017400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.060300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.005400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.107500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.262800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.111200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.758600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.723200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.646600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.642500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.587600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.562800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.353800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.403600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.373800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.254100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.221600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.739700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.424600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.247400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.176200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.123200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.031900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.195300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.114600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.059000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.057000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.068300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.175700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.216500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.095900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.055300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.079200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.065900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.060400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.066200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.051000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.047300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.027100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.023000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.011700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.027600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.021600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.022400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.014600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.009500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.011200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.040200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.010800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.028700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.011900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.013000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.017600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.006800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.026500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.011700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.012800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.007300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.006600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.011700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.013200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.007500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.007800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.014800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.006900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.008700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.007600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.006000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.016400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0.004200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.009200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>0.004900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.006000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.007400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=930, training_loss=0.45825855641034985, metrics={'train_runtime': 599.6823, 'train_samples_per_second': 3.102, 'train_steps_per_second': 1.551, 'total_flos': 29360217566880.0, 'train_loss': 0.45825855641034985, 'epoch': 15.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4681953-a97a-41a1-8bb7-a4b327113cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./intent_model\\\\tokenizer_config.json',\n",
       " './intent_model\\\\special_tokens_map.json',\n",
       " './intent_model\\\\vocab.txt',\n",
       " './intent_model\\\\added_tokens.json',\n",
       " './intent_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./intent_model\")\n",
    "tokenizer.save_pretrained(\"./intent_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43f8d9d5-c3ef-42f1-a4b0-e25fc2a8bb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'admission_process', 1: 'eligibility', 2: 'fees_info', 3: 'admission_dates', 4: 'user_info', 5: 'document_requirements', 6: 'evaluation_process', 7: 'contact_info', 8: 'scholarship_info', 9: 'technical_support', 10: 'academic_details', 11: 'campus_life'}\n"
     ]
    }
   ],
   "source": [
    "intent_labels = {label: i for i, label in enumerate(df['Intent'].unique())}\n",
    "\n",
    "id2label = {v: k for k, v in intent_labels.items()}\n",
    "\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52ffdaa3-9320-4be7-8f6b-eab71ba26a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: I want to know about admission process\n",
      "Predicted Intent: evaluation_process\n",
      "\n",
      "Query: What are the fees for MBA?\n",
      "Predicted Intent: fees_info\n",
      "\n",
      "Query: Eligibility criteria for BTech?\n",
      "Predicted Intent: admission_process\n",
      "\n",
      "Query: how can i contact perticulaar college\n",
      "Predicted Intent: evaluation_process\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "intent_classifier = pipeline(\"text-classification\", model=\"./intent_model\", tokenizer=\"./intent_model\")\n",
    "\n",
    "examples = [\n",
    "    \"I want to know about admission process\",\n",
    "    \"What are the fees for MBA?\",\n",
    "    \"Eligibility criteria for BTech?\",\n",
    "    \"\"\n",
    "]\n",
    "\n",
    "for text in examples:\n",
    "    result = intent_classifier(text)\n",
    "    label_idx = int(result[0]['label'].split(\"_\")[1])\n",
    "    intent_name = id2label[label_idx]\n",
    "    print(f\"Query: {text}\")\n",
    "    print(f\"Predicted Intent: {intent_name}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
